
# AI-Powered Product Recommendation Engine

This project is designed to showcase my ability to work with large language models (LLMs), engineer effective prompts, design robust backend services, and build a functional user interface for an eCommerce recommendation system.

## Overview

The goal of this project is to build a simplified product recommendation system that generates personalized recommendations based on user preferences and browsing history. The system leverages an LLM via the Replicate API (using the `meta/meta-llama-3-8b-instruct` model) to produce recommendations in a structured JSON format.

While the starter kit provided a full-stack structure (with a React frontend), I chose to focus on the backend—my area of expertise—and used Streamlit for the frontend. This allowed me to rapidly prototype a functional UI while dedicating significant effort to prompt engineering, API integration, and error handling.

## Features

- **Context-Rich Recommendations:**  
  Combines user preferences, browsing history, and a sample product catalog to build detailed prompts for the LLM.
  
- **Structured Output:**  
  The system instructs the LLM to output recommendations in a strict JSON format (with product ID, explanation, and confidence score) for easier parsing.

- **Robust Error Handling:**  
  Implements extensive error handling to manage API failures and parsing issues, ensuring the application remains stable.

- **Advanced Filtering:**  
  The product catalog is filtered on the frontend based on user-selected criteria (price range, categories, and brands).

- **Caching:**  
  Caches LLM responses based on a hash of the prompt to reduce redundant API calls and improve performance.

## Project Architecture

### Backend

- **config.py:**  
  Loads environment variables (e.g., the Replicate API token) to manage sensitive information securely.

- **services/llm_service.py:**  
  Contains the `LLMService` class, which is responsible for:
  - Constructing prompts from user preferences, browsing history, and product data.
  - Calling the Replicate API to generate recommendations.
  - Parsing the model's output (even when it contains extra text) to extract valid JSON.
  - Caching responses for performance optimization.

- **data/products.json:**  
  A sample product catalog containing details such as product ID, name, category, price, brand, description, features, rating, inventory, and tags.

- **app.py (Streamlit):**  
  Serves as the main entry point and UI layer. It:
  - Displays a filtered product catalog.
  - Allows users to set preferences and simulate browsing history.
  - Shows personalized product recommendations with explanations and confidence scores.

### Frontend

I used **Streamlit** for the frontend due to its rapid prototyping capabilities and my familiarity with it. This choice allowed me to deliver a clean, interactive UI without the overhead of a full React implementation.


## Setup Instructions

### Prerequisites

- Python 3.10 or later
- [pip](https://pip.pypa.io/en/stable/)
- (Optional) A virtual environment tool (e.g., `venv`)

### Backend Setup

1. **Clone the Repository:**
```bash
   git clone https://github.com/kollaikal/ai-product-recommendation-engine.git
   cd ai-product-recommendation-engine/backend
```
2. Create and Activate a Virtual Environment:
```
python -m venv venv
# On macOS/Linux:
source venv/bin/activate
# On Windows:
venv\Scripts\activate
```
3. Install Dependencies:
```
pip install -r requirements.txt
```
4. Configure Environment Variables:

Create a .env file in the project root (or in the backend folder) with the following content:
```
REPLICATE_API_TOKEN=your_replicate_api_token_here
```
I have have used Replicate API. You can replace it with any other LLM API of your choice. 

5. Run the Application:
```
streamlit run app.py
```
The application should open in your browser at http://localhost:8501.

## Frontend (Streamlit)
The Streamlit UI allows you to:

Select user preferences (price range, categories, brands) from a sidebar.

View a product catalog filtered by your selected criteria.

Simulate browsing history by clicking on products.

Receive personalized recommendations generated by the LLM, complete with explanations and confidence scores.

## Testing & Validation
Local Testing:
I tested the LLM service with dummy data to ensure the output is valid JSON and maps correctly to the product catalog.

## End-to-End Testing:
The complete system was tested via the Streamlit UI to simulate real user interactions.

## Edge Cases:
Extensive error handling has been implemented to gracefully handle cases where the API response is incomplete or contains extraneous text.

## Future Enhancements
User Authentication:
Incorporate authentication to allow persistent user profiles and personalized recommendation histories.

Persistent Caching:
Move from in-memory caching to a persistent caching mechanism for production use.

Enhanced Filtering & Sorting:
Add dynamic sorting, multi-attribute filtering, and advanced search features to the product catalog.

Comprehensive Testing:
Expand unit and integration tests to further ensure robustness and maintainability.

## Conclusion
This project showcases my ability to build a scalable, AI-powered product recommendation engine using robust prompt engineering techniques and a modular backend design. The decision to use Streamlit for the frontend reflects my focus on delivering a functional and efficient solution quickly, allowing me to concentrate on the core technical challenges.

